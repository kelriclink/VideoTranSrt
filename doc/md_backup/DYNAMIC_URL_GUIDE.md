# 动态URL获取功能说明

## 功能概述

现在程序具备了动态获取Whisper模型下载地址的功能，每次进入模型管理页面时都会自动获取最新的下载链接。

## 新增功能

### 1. 动态URL获取
- **自动检测**: 程序会自动检测多个下载源的可用性
- **智能选择**: 选择最快、最稳定的下载地址
- **实时更新**: 每次进入模型管理页面都会刷新URL

### 2. 多重下载源
程序会按优先级尝试以下下载源：

1. **HuggingFace** (优先级最高)
   - `https://huggingface.co/openai/whisper-{size}/resolve/main/pytorch_model.bin`

2. **GitHub Releases** (备用)
   - `https://github.com/openai/whisper/releases/download/v20231117/whisper-{size}.pt`

3. **OpenAI官方** (备用)
   - `https://openaipublic.azureedge.net/whisper/models/...`

### 3. GUI增强功能

**模型管理页面新增按钮：**
- 🔄 **刷新下载地址** - 手动刷新所有下载地址
- ⬆️ **上传模型** - 上传本地模型文件
- 🌐 **自定义下载** - 使用自定义URL下载
- 📋 **手动下载** - 查看详细下载说明

## 使用方法

### 启动GUI
```bash
python run.py gui
```

### 使用动态下载
1. 打开设置 → 模型管理
2. 点击"刷新下载地址"查看当前可用地址
3. 点击"下载"按钮，程序会自动选择最佳URL
4. 实时查看下载进度

### 查看下载地址
1. 点击"刷新下载地址"按钮
2. 查看所有模型的可用下载地址
3. 每个地址都会显示可用性状态

## 技术实现

### 核心功能
- **URL检测**: 自动测试每个下载地址的可用性
- **智能选择**: 选择响应最快的可用地址
- **缓存机制**: 缓存URL信息，提高性能
- **错误处理**: 完善的异常处理和重试机制

### 支持的模型
| 模型 | 大小 | 下载源数量 | 推荐场景 |
|------|------|------------|----------|
| tiny | 39MB | 3个源 | 快速测试 |
| base | 74MB | 3个源 | **日常使用** |
| small | 244MB | 3个源 | 平衡需求 |
| medium | 769MB | 3个源 | 高质量需求 |
| large | 1550MB | 3个源 | 专业用途 |

## 故障排除

### 问题1: 所有下载源都不可用
**解决方案**:
1. 检查网络连接
2. 尝试使用VPN
3. 使用手动下载功能
4. 上传本地模型文件

### 问题2: 下载速度慢
**解决方案**:
1. 点击"刷新下载地址"选择更快的源
2. 使用自定义下载功能
3. 手动下载后上传

### 问题3: SSL证书问题
**解决方案**:
- 程序已自动处理SSL问题
- 如果仍有问题，设置环境变量: `set PYTHONHTTPSVERIFY=0`

## 优势

1. **自动化**: 无需手动查找下载地址
2. **可靠性**: 多个备用源确保下载成功
3. **实时性**: 始终使用最新的下载地址
4. **用户友好**: 一键刷新和下载
5. **智能选择**: 自动选择最佳下载源

## 更新日志

- ✅ 实现动态URL获取功能
- ✅ 添加多重下载源支持
- ✅ 集成GUI刷新功能
- ✅ 完善错误处理机制
- ✅ 添加URL可用性检测

现在您可以享受更稳定、更智能的模型下载体验！🎉
